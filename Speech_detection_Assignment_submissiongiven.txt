{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    },
    "colab": {
      "name": "Speech_detection_Assignment_submissiongiven.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6V5SaD9D9pD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwoTWIysaNmc"
      },
      "source": [
        "<pre><font size=6>Spoken Digit Recognition</font></pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPO3mjDDaNmf"
      },
      "source": [
        "<pre>\n",
        "In this notebook, You will do Spoken Digit Recognition. \n",
        "\n",
        "Input - speech signal, output - digit number\n",
        "\n",
        "\n",
        "\n",
        "It contains  \n",
        "\n",
        "1. Reading the dataset. and Preprocess the data set. Detailed instrctions are given below. You have to write the code in the same cell which contains the instrction. \n",
        "2. Training the LSTM with RAW data\n",
        "3. Converting to spectrogram and Training the LSTM network\n",
        "4. Creating the augmented data and doing step 2 and 3 again.  \n",
        "\n",
        "<font size=5>instructions:</font>\n",
        "\n",
        "    1. Don't change any Grader Functions. Don't manipulate any Grader functions. If you manipulate any, it will be considered as plagiarised. \n",
        "    \n",
        "    2. Please read the instructions on the code cells and markdown cells. We will explain what to write. \n",
        "    \n",
        "    3. please return outputs in the same format what we asked. Eg. Don't return List of we are asking for a numpy array.\n",
        "    \n",
        "    4. Please read the external links that we are given so that you will learn the concept behind the code that you are writing.\n",
        "    \n",
        "    5. We are giving instructions at each section if necessary, please follow them. \n",
        "\n",
        "<font size=5>Every Grader function has to return True. </font>\n",
        "\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qGuPcj-aNmh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "390dd05a-351a-445b-d838-c702f2220a61"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import os\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/MyDrive/Applied_ai/spoken_digit/')\n",
        "!pip install tensorflow-addons\n",
        "##if you need any imports you can do that here. "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.14.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdhFzGK1aNmo"
      },
      "source": [
        "We shared recordings.zip, please unzip those. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDBcl_PUaNmp"
      },
      "source": [
        "#read the all file names in the recordings folder given by us\n",
        "#(if you get entire path, it is very useful in future)\n",
        "#save those files names as list in \"all_files\"\n",
        "all_files = os.listdir('recordings')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NYYpfqoaNmv"
      },
      "source": [
        "<font size=4>Grader function 1 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oJSOmYBaNmx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1c8ec65-fb9a-401d-dda1-ed22d8c9f1fe"
      },
      "source": [
        "def grader_files():\n",
        "    temp = len(all_files)==2000\n",
        "    temp1 = all([x[-3:]==\"wav\" for x in all_files])\n",
        "    temp = temp and temp1\n",
        "    return temp\n",
        "grader_files()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhvSIN6raNm3"
      },
      "source": [
        "Create a dataframe(name=df_audio) with two columns(path, label).   \n",
        "You can get the label from the first letter of name.  \n",
        "Eg: 0_jackson_0 --> 0  \n",
        "0_jackson_43 --> 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWP6vXBeaNm3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "outputId": "d8710a5f-8d34-4a8d-d222-beac97f71775"
      },
      "source": [
        "#Create a dataframe(name=df_audio) with two columns(path, label).   \n",
        "#You can get the label from the first letter of name.  \n",
        "#Eg: 0_jackson_0 --> 0  \n",
        "#0_jackson_43 --> 0\n",
        "pathlist = list(map(lambda x: x.split('_')[0] ,all_files))\n",
        "all_files = list(map(lambda x: 'recordings/'+x ,all_files))\n",
        "data = {'path':all_files,\n",
        "        'label':pathlist}\n",
        " \n",
        "# Create DataFrame\n",
        "df_audio = pd.DataFrame(data)\n",
        " \n",
        "# Print the output.\n",
        "df_audio"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>recordings/0_jackson_9.wav</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>recordings/9_jackson_7.wav</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>recordings/0_jackson_6.wav</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>recordings/8_theo_45.wav</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>recordings/6_yweweler_40.wav</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>recordings/6_theo_34.wav</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>recordings/1_yweweler_37.wav</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>recordings/8_yweweler_17.wav</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>recordings/5_theo_31.wav</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>recordings/0_jackson_44.wav</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                              path label\n",
              "0       recordings/0_jackson_9.wav     0\n",
              "1       recordings/9_jackson_7.wav     9\n",
              "2       recordings/0_jackson_6.wav     0\n",
              "3         recordings/8_theo_45.wav     8\n",
              "4     recordings/6_yweweler_40.wav     6\n",
              "...                            ...   ...\n",
              "1995      recordings/6_theo_34.wav     6\n",
              "1996  recordings/1_yweweler_37.wav     1\n",
              "1997  recordings/8_yweweler_17.wav     8\n",
              "1998      recordings/5_theo_31.wav     5\n",
              "1999   recordings/0_jackson_44.wav     0\n",
              "\n",
              "[2000 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZpuaGuJaNm8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05008ef5-ed11-416c-cf3f-2407573acdb7"
      },
      "source": [
        "#info\n",
        "df_audio.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2000 entries, 0 to 1999\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   path    2000 non-null   object\n",
            " 1   label   2000 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 31.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOKpYJ_LaNnD"
      },
      "source": [
        "<font size=4>Grader function 2 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Q8r_T8-aNnE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1f5bee7-ed8e-4717-b275-9ab361dca606"
      },
      "source": [
        "def grader_df():\n",
        "    flag_shape = df_audio.shape==(2000,2)\n",
        "    flag_columns = all(df_audio.columns==['path', 'label'])\n",
        "    list_values = list(df_audio.label.value_counts())\n",
        "    flag_label = len(list_values)==10\n",
        "    flag_label2 = all([i==200 for i in list_values])\n",
        "    final_flag = flag_shape and flag_columns and flag_label and flag_label2\n",
        "    return final_flag\n",
        "grader_df()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlfssCc3aNnL"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "df_audio = shuffle(df_audio, random_state=33)#don't change the random state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZ448aENaNnR"
      },
      "source": [
        "<pre><font size=4>Train and Validation split</font></pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSPy-Ln6aNnS"
      },
      "source": [
        "#split the data into train and validation and save in X_train, X_test, y_train, y_test\n",
        "#use stratify sampling\n",
        "#use random state of 45\n",
        "#use test size of 30%\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df_audio['path'], df_audio['label'], test_size=0.3, random_state=45,stratify=df_audio['label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPK3sbzUaNnW"
      },
      "source": [
        "<font size=4>Grader function 3 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chZzntKUaNnX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6052547-e054-4374-cad2-57c719c52b4e"
      },
      "source": [
        "def grader_split():\n",
        "    flag_len = (len(X_train)==1400) and (len(X_test)==600) and (len(y_train)==1400) and (len(y_test)==600)\n",
        "    values_ytrain = list(y_train.value_counts())\n",
        "    flag_ytrain = (len(values_ytrain)==10) and (all([i==140 for i in values_ytrain]))\n",
        "    values_ytest = list(y_test.value_counts())\n",
        "    flag_ytest = (len(values_ytest)==10) and (all([i==60 for i in values_ytest]))\n",
        "    final_flag = flag_len and flag_ytrain and flag_ytest\n",
        "    return final_flag\n",
        "grader_split()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGhh-39vaNnb"
      },
      "source": [
        "<pre><font size=4>Preprocessing</font>\n",
        "\n",
        "All files are in the \"WAV\" format. We will read those raw data files using the librosa</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i99JacQSaNnc"
      },
      "source": [
        "sample_rate = 22050\n",
        "def load_wav(x, get_duration=True):\n",
        "    '''This return the array values of audio with sampling rate of 22050 and Duration'''\n",
        "    #loading the wav file with sampling rate of 22050\n",
        "    samples, sample_rate = librosa.load(x, sr=22050)\n",
        "    if get_duration:\n",
        "        duration = librosa.get_duration(samples, sample_rate)\n",
        "        return [samples, duration]\n",
        "    else:\n",
        "        return samples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rx97f8GGaNnh"
      },
      "source": [
        "#use load_wav function that was written above to get every wave. \n",
        "#save it in X_train_processed and X_test_processed\n",
        "# X_train_processed/X_test_processed should be dataframes with two columns(raw_data, duration) with same index of X_train/y_train\n",
        "X_train_processed={'raw_data':[] , 'duration':[]}\n",
        "X_test_processed={'raw_data':[] , 'duration':[]}\n",
        "for i in X_train:\n",
        "  \n",
        "  s ,d = load_wav(i,True)\n",
        "  X_train_processed['raw_data'].append(s)\n",
        "  X_train_processed['duration'].append(d)\n",
        "for i in X_test:\n",
        "  s ,d = load_wav(i,True)\n",
        "  X_test_processed['raw_data'].append(s)\n",
        "  X_test_processed['duration'].append(d)\n",
        "\n",
        "X_train_processed = pd.DataFrame(X_train_processed)\n",
        "X_test_processed = pd.DataFrame(X_test_processed)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "bC5cf7dYQJt6",
        "outputId": "b98a6b81-f1a3-4058-ca61-8faa386120af"
      },
      "source": [
        "X_test_processed"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>raw_data</th>\n",
              "      <th>duration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[-0.00026846927, -0.0063553923, -0.012668992, ...</td>\n",
              "      <td>0.406667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[8.158055e-05, -0.00023039251, -0.0006341855, ...</td>\n",
              "      <td>0.364535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[-0.03756839, -0.031839468, -0.016046075, 0.00...</td>\n",
              "      <td>0.516644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[-0.00050216826, 2.7594652e-07, 0.00022539018,...</td>\n",
              "      <td>0.459138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[-0.009488059, -0.014710673, -0.015785733, -0....</td>\n",
              "      <td>0.422902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>595</th>\n",
              "      <td>[-0.00028627977, -0.00032097072, -0.0002687732...</td>\n",
              "      <td>0.416417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>596</th>\n",
              "      <td>[0.000958262, -0.00032280156, -0.0013338974, -...</td>\n",
              "      <td>0.228027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>597</th>\n",
              "      <td>[-0.0077094454, 0.0034615246, 0.014049837, 0.0...</td>\n",
              "      <td>0.276009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>598</th>\n",
              "      <td>[-0.0002486257, -0.00029508976, -0.00026771644...</td>\n",
              "      <td>0.180408</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>599</th>\n",
              "      <td>[-0.009432797, -0.011613886, -0.012274079, -0....</td>\n",
              "      <td>0.623039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>600 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              raw_data  duration\n",
              "0    [-0.00026846927, -0.0063553923, -0.012668992, ...  0.406667\n",
              "1    [8.158055e-05, -0.00023039251, -0.0006341855, ...  0.364535\n",
              "2    [-0.03756839, -0.031839468, -0.016046075, 0.00...  0.516644\n",
              "3    [-0.00050216826, 2.7594652e-07, 0.00022539018,...  0.459138\n",
              "4    [-0.009488059, -0.014710673, -0.015785733, -0....  0.422902\n",
              "..                                                 ...       ...\n",
              "595  [-0.00028627977, -0.00032097072, -0.0002687732...  0.416417\n",
              "596  [0.000958262, -0.00032280156, -0.0013338974, -...  0.228027\n",
              "597  [-0.0077094454, 0.0034615246, 0.014049837, 0.0...  0.276009\n",
              "598  [-0.0002486257, -0.00029508976, -0.00026771644...  0.180408\n",
              "599  [-0.009432797, -0.011613886, -0.012274079, -0....  0.623039\n",
              "\n",
              "[600 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "Rcq8OplFQjit",
        "outputId": "e67d5af4-b3ea-4e24-9785-8fab4b0f342c"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.histplot(data=X_train_processed, x=\"duration\",binwidth=0.25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fab0fa86190>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "c2efY_ZeTN7m",
        "outputId": "31b3251b-3ca5-40e1-c863-4567b39d2dfe"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.histplot(data=X_test_processed, x=\"duration\",binwidth=0.25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f774e691750>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZurNa9TVtnf",
        "outputId": "44a21e87-f37d-4aae-f72a-52e3e5dd938f"
      },
      "source": [
        "list(range(0,110,10))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvkojia1TwOE",
        "outputId": "26b2ac48-2935-4622-aef5-a00ee9fdb7d2"
      },
      "source": [
        "#print 0 to 100 percentile values with step size of 10 for train data duration.\n",
        "p = np.percentile(X_train_processed['duration'], range(0,110,10))\n",
        "for i,j in enumerate(p):\n",
        "  print(str(i*10)+' th percentile is '+str(j) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 th percentile is 0.1435374149659864\n",
            "10 th percentile is 0.2601224489795918\n",
            "20 th percentile is 0.30038095238095236\n",
            "30 th percentile is 0.33215419501133786\n",
            "40 th percentile is 0.35699773242630384\n",
            "50 th percentile is 0.385827664399093\n",
            "60 th percentile is 0.4149297052154195\n",
            "70 th percentile is 0.4451972789115646\n",
            "80 th percentile is 0.4821587301587302\n",
            "90 th percentile is 0.5538775510204081\n",
            "100 th percentile is 2.282766439909297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MU2yIIGEbG6i",
        "outputId": "2b51f4ae-f7f6-4d54-a4f1-80772aba62a1"
      },
      "source": [
        "#print 0 to 100 percentile values with step size of 10 for test data duration.\n",
        "p = np.percentile(X_train_processed['duration'], range(90,101))\n",
        "for i,j in enumerate(p):\n",
        "  print(str(i+90)+' th percentile is '+str(j))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90 th percentile is 0.5538775510204081\n",
            "91 th percentile is 0.5642412698412701\n",
            "92 th percentile is 0.5778757369614514\n",
            "93 th percentile is 0.5938775510204082\n",
            "94 th percentile is 0.610431746031746\n",
            "95 th percentile is 0.6231315192743764\n",
            "96 th percentile is 0.6420553287981859\n",
            "97 th percentile is 0.6587115646258503\n",
            "98 th percentile is 0.6896798185941042\n",
            "99 th percentile is 0.790681179138322\n",
            "100 th percentile is 2.282766439909297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbMb4Y0RaNoA"
      },
      "source": [
        "<font size=4>Grader function 4 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMoyLLSAaNoF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cdd06dc-984a-4a2c-bcdd-b79cfef913f4"
      },
      "source": [
        "def grader_processed():\n",
        "    flag_columns = (all(X_train_processed.columns==['raw_data', 'duration'])) and (all(X_test_processed.columns==['raw_data', 'duration']))\n",
        "    flag_shape = (X_train_processed.shape ==(1400, 2)) and (X_test_processed.shape==(600,2))\n",
        "    return flag_columns and flag_shape\n",
        "grader_processed()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cux3_jfcaNoM"
      },
      "source": [
        "<pre>Based on our analysis 99 percentile values are less than 0.8sec so we will limit maximum length of X_train_processed and X_test_processed to 0.8 sec. It is similar to pad_sequence for a text dataset. \n",
        "\n",
        "While loading the audio files, we are using sampling rate of 22050 so one sec will give array of length 22050. so, our maximum length is 0.8*22050 = 17640\n",
        "\n",
        "Pad with Zero if length of sequence is less than 17640 else Truncate the number. \n",
        "\n",
        "Also create a masking vector for train and test. \n",
        "\n",
        "masking vector value = 1 if it is real value, 0 if it is pad value. Masking vector data type must be bool.\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voqSEyvcaNoO"
      },
      "source": [
        "max_length  = 17640"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1-_r20BaNoW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad64e341-0c29-4921-da5a-35198e9fbd74"
      },
      "source": [
        "## as discussed above, Pad with Zero if length of sequence is less than 17640 else Truncate the number. \n",
        "## save in the X_train_pad_seq, X_test_pad_seq\n",
        "## also Create masking vector X_train_mask, X_test_mask\n",
        "\n",
        "## all the X_train_pad_seq, X_test_pad_seq, X_train_mask, X_test_mask will be numpy arrays mask vector dtype must be bool.\n",
        "X_train_pad_seq = None\n",
        "X_train_mask = None\n",
        "for k,i in enumerate(X_train_processed['raw_data']):\n",
        "  if k == 0:\n",
        "    X_train_pad_seq =  np.append( i[0:17640],np.zeros(max( 17640 - i.shape[0] , 0))).reshape(1,-1)\n",
        "    X_train_mask = np.append( np.ones(i[0:17640].shape[0]),np.zeros(max( 17640 - i.shape[0] , 0))).reshape(1,-1)\n",
        "    continue\n",
        "  X_train_pad_seq = np.append(X_train_pad_seq , np.append( i[0:17640],np.zeros(max( 17640 - i.shape[0] , 0))).reshape(1,-1), axis=0)\n",
        "  X_train_mask =  np.append(X_train_mask,np.append( np.ones(i[0:17640].shape[0]),np.zeros(max( 17640 - i.shape[0] , 0))).reshape(1,-1), axis=0)\n",
        "\n",
        "X_test_pad_seq = None\n",
        "X_test_mask = None\n",
        "for k,i in enumerate(X_test_processed['raw_data']):\n",
        "  if k == 0:\n",
        "    X_test_pad_seq =  np.append( i[0:17640],np.zeros(max( 17640 - i.shape[0] , 0))).reshape(1,-1)\n",
        "    X_test_mask = np.append( np.ones(i[0:17640].shape[0]),np.zeros(max( 17640 - i.shape[0] , 0))).reshape(1,-1)\n",
        "    continue\n",
        "  X_test_pad_seq = np.append(X_test_pad_seq , np.append( i[0:17640],np.zeros(max( 17640 - i.shape[0] , 0))).reshape(1,-1), axis=0)\n",
        "  X_test_mask =  np.append(X_test_mask,np.append( np.ones(i[0:17640].shape[0]),np.zeros(max( 17640 - i.shape[0] , 0))).reshape(1,-1), axis=0)\n",
        "\n",
        "X_train_mask.astype('bool')     \n",
        "X_test_mask.astype('bool')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ True,  True,  True, ..., False, False, False],\n",
              "       [ True,  True,  True, ..., False, False, False],\n",
              "       [ True,  True,  True, ..., False, False, False],\n",
              "       ...,\n",
              "       [ True,  True,  True, ..., False, False, False],\n",
              "       [ True,  True,  True, ..., False, False, False],\n",
              "       [ True,  True,  True, ..., False, False, False]])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEHMgm4DaNoe"
      },
      "source": [
        "<font size=4>Grader function 5 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxLSPO1QBJDT",
        "outputId": "123fa34d-8f0a-4e21-9c4e-68aa57c01ffb"
      },
      "source": [
        "X_train_mask = X_train_mask.astype('bool')     \n",
        "X_test_mask = X_test_mask.astype('bool')\n",
        "X_train_mask.dtype"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('bool')"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Th3KhplGaNof",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1b0d04a-f84a-482e-fe17-b7b32e35b576"
      },
      "source": [
        "def grader_padoutput():\n",
        "    flag_padshape = (X_train_pad_seq.shape==(1400, 17640)) and (X_test_pad_seq.shape==(600, 17640)) and (y_train.shape==(1400,))\n",
        "    flag_maskshape = (X_train_mask.shape==(1400, 17640)) and (X_test_mask.shape==(600, 17640)) and (y_test.shape==(600,))\n",
        "    flag_dtype = (X_train_mask.dtype==bool) and (X_test_mask.dtype==bool)\n",
        "    return flag_padshape and flag_maskshape and flag_dtype\n",
        "grader_padoutput()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjQxuxlrB6eK"
      },
      "source": [
        "# np.save('X_train_pad_seq.npy', X_train_pad_seq)\n",
        "# np.save('X_train_mask.npy', X_train_mask) \n",
        "# np.save('y_train.npy', y_train)\n",
        "# np.save('X_test_pad_seq.npy', X_test_pad_seq)\n",
        "# np.save('X_test_mask.npy', X_test_mask) \n",
        "# np.save('y_test.npy', y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vs0apceUJ2uc"
      },
      "source": [
        "X_train_pad_seq = np.load('X_train_pad_seq.npy',allow_pickle=True)\n",
        "X_train_mask = np.load('X_train_mask.npy',allow_pickle=True) \n",
        "y_train = np.load('y_train.npy',allow_pickle=True)\n",
        "X_test_pad_seq = np.load('X_test_pad_seq.npy',allow_pickle=True)\n",
        "X_test_mask = np.load('X_test_mask.npy',allow_pickle=True) \n",
        "y_test = np.load('y_test.npy',allow_pickle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0kaYQ1jaNop"
      },
      "source": [
        "### 1. Giving Raw data directly. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGHxh3jTaNoq"
      },
      "source": [
        "<pre>\n",
        "Now we have\n",
        "\n",
        "Train data: X_train_pad_seq, X_train_mask and y_train  \n",
        "Test data: X_test_pad_seq, X_test_mask and y_test   \n",
        "\n",
        "We will create a LSTM model which takes this input. \n",
        "\n",
        "Task:\n",
        "\n",
        "1. Create an LSTM network which takes \"X_train_pad_seq\" as input, \"X_train_mask\" as mask input. You can use any number of LSTM cells. Please read LSTM documentation(https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM) in tensorflow to know more about mask and also https://www.tensorflow.org/guide/keras/masking_and_padding \n",
        "2. Get the final output of the LSTM and give it to Dense layer of any size and then give it to Dense layer of size 10(because we have 10 outputs) and then compile with the sparse categorical cross entropy( because we are not converting it to one hot vectors). \n",
        "3. Use tensorboard to plot the graphs of loss and metric(use micro F1 score as metric) and histograms of gradients. \n",
        "4. make sure that it won't overfit. \n",
        "5. You are free to include any regularization\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ne46mDYiEBOu"
      },
      "source": [
        "#train your model\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "def microf1score(y_true, y_pred):\n",
        "    y_true=y_true.numpy()\n",
        "    y_true = enc.transform(y_true)\n",
        "    y_true = y_true.todense()\n",
        "    microf1 = tfa.metrics.F1Score(num_classes=10, threshold=0.5 , average='micro')\n",
        "    microf1.update_state(y_true, y_pred)\n",
        "    return microf1.result().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZ3qXzF7Dq-Z"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def microf1(y_true, y_pred):\n",
        "    y_true=y_true.numpy()\n",
        "    y_true = enc.transform(y_true)\n",
        "    y_true = y_true.todense()\n",
        "    y_pred = y_pred.numpy()\n",
        "    y_new_pred = np.array([])\n",
        "    for i,j in enumerate(y_pred):\n",
        "      if i == 0:\n",
        "        y_new_pred =  np.zeros(len(j)).reshape(1,-1)\n",
        "        y_new_pred[0][np.argmax(j)] = 1 \n",
        "        continue\n",
        "      y_new_append = np.zeros(len(j))\n",
        "      y_new_append[np.argmax(j)] = 1\n",
        "      y_new_pred = np.append(y_new_pred,y_new_append.reshape(1,-1), axis=0)\n",
        "      \n",
        "    return f1_score(y_true, y_new_pred, average='micro')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TZvfiCp8-mo",
        "outputId": "9dab737e-6d81-4b7e-d58c-17f9f45ffc2b"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "y_train_fit = np.array([ [int(i)] for i in y_train])\n",
        "enc.fit(y_train_fit)\n",
        "\n",
        "enc.categories_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8yg951AaNor"
      },
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Dense,Embedding\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "max_length  = 17640\n",
        "input_padded = Input(shape = (max_length, 1),name= 'input_padded')\n",
        "input_masked = Input(shape = (max_length), dtype='bool' ,name= 'input_masked')\n",
        "lstm = LSTM(50)(input_padded, mask = input_masked)\n",
        "dense = Dense(50, 'relu')(lstm)\n",
        "output = Dense(10, 'softmax')(dense)\n",
        "model = Model(inputs = [input_padded, input_masked], outputs = output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8y1sgeVaNoy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f65ad75f-3341-4ff9-e1d5-abba99cf2749"
      },
      "source": [
        "## as discussed above, please write the LSTM\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_padded (InputLayer)       [(None, 17640, 1)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_masked (InputLayer)       [(None, 17640)]      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 50)           10400       input_padded[0][0]               \n",
            "                                                                 input_masked[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 50)           2550        lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           510         dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 13,460\n",
            "Trainable params: 13,460\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzpPjxvHaNpJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9634fe9-a322-40d4-8dfa-4e0ab46119c6"
      },
      "source": [
        "#train your model\n",
        "import datetime\n",
        "\n",
        "earlystop = EarlyStopping(monitor='val_accuracy', min_delta=0.0000001, patience=5, verbose=1,mode='auto')\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "#microf1score = tfa.metrics.F1Score(num_classes=3, threshold=0.5 , average='micro')\n",
        "model.compile(optimizer=optimizer,loss='sparse_categorical_crossentropy',metrics=['accuracy',microf1],run_eagerly=True)\n",
        "\n",
        "log_dir=\"logs/fit/\" + 'model2.'+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=1, write_graph=True,write_grads=True)\n",
        "\n",
        "y_train = [int(i) for i in y_train]\n",
        "y_test = [int(i) for i in y_test]\n",
        "\n",
        "model.fit(x=[X_train_pad_seq.reshape(1400,17640,1),X_train_mask.astype('bool')],y=np.array(y_train),epochs=50,validation_data=([X_test_pad_seq.reshape(600,17640,1),X_test_mask.astype('bool')],np.array(y_test) ),callbacks=[earlystop,tensorboard_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n",
            "Epoch 1/50\n",
            "44/44 [==============================] - 102s 2s/step - loss: 2.3034 - accuracy: 0.0821 - microf1: 0.0819 - val_loss: 2.3026 - val_accuracy: 0.1000 - val_microf1: 0.0992\n",
            "Epoch 2/50\n",
            "44/44 [==============================] - 88s 2s/step - loss: 2.3030 - accuracy: 0.0829 - microf1: 0.0826 - val_loss: 2.3026 - val_accuracy: 0.1000 - val_microf1: 0.0998\n",
            "Epoch 3/50\n",
            "44/44 [==============================] - 89s 2s/step - loss: 2.3030 - accuracy: 0.0936 - microf1: 0.0938 - val_loss: 2.3026 - val_accuracy: 0.0967 - val_microf1: 0.0970\n",
            "Epoch 4/50\n",
            "44/44 [==============================] - 84s 2s/step - loss: 2.3029 - accuracy: 0.0964 - microf1: 0.0964 - val_loss: 2.3026 - val_accuracy: 0.1000 - val_microf1: 0.0998\n",
            "Epoch 5/50\n",
            "44/44 [==============================] - 84s 2s/step - loss: 2.3030 - accuracy: 0.0829 - microf1: 0.0826 - val_loss: 2.3026 - val_accuracy: 0.1017 - val_microf1: 0.1014\n",
            "Epoch 6/50\n",
            "44/44 [==============================] - 85s 2s/step - loss: 2.3029 - accuracy: 0.0986 - microf1: 0.0982 - val_loss: 2.3026 - val_accuracy: 0.1017 - val_microf1: 0.1020\n",
            "Epoch 7/50\n",
            "44/44 [==============================] - 84s 2s/step - loss: 2.3028 - accuracy: 0.0857 - microf1: 0.0859 - val_loss: 2.3026 - val_accuracy: 0.1017 - val_microf1: 0.1025\n",
            "Epoch 8/50\n",
            "44/44 [==============================] - 88s 2s/step - loss: 2.3030 - accuracy: 0.0836 - microf1: 0.0840 - val_loss: 2.3025 - val_accuracy: 0.1017 - val_microf1: 0.1014\n",
            "Epoch 9/50\n",
            "44/44 [==============================] - 85s 2s/step - loss: 2.3030 - accuracy: 0.0793 - microf1: 0.0795 - val_loss: 2.3025 - val_accuracy: 0.1017 - val_microf1: 0.1020\n",
            "Epoch 10/50\n",
            "44/44 [==============================] - 88s 2s/step - loss: 2.3028 - accuracy: 0.0843 - microf1: 0.0838 - val_loss: 2.3025 - val_accuracy: 0.1017 - val_microf1: 0.1014\n",
            "Epoch 00010: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd82590d950>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfpttczBIC-g"
      },
      "source": [
        "- Here micro f1 score and acciracy is nearly same becase while calculating microf1 score we collective consider all classes for recall and precision "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Fwk0X4zaNpR"
      },
      "source": [
        "### 2. Converting into spectrogram and giving spectrogram data as input  \n",
        "<pre>\n",
        "We can use librosa to convert raw data into spectrogram. A spectrogram shows the features in a two-dimensional representation with the\n",
        "intensity of a frequency at a point in time i.e we are converting Time domain to frequency domain. you can read more about this in https://pnsn.org/spectrograms/what-is-a-spectrogram\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nb5AGzTjaNpS"
      },
      "source": [
        "def convert_to_spectrogram(raw_data):\n",
        "    '''converting to spectrogram'''\n",
        "    spectrum = librosa.feature.melspectrogram(y=raw_data, sr=17640, n_mels=64)\n",
        "    logmel_spectrum = librosa.power_to_db(S=spectrum, ref=np.max)\n",
        "    return logmel_spectrum"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B__rN4RjaNpc"
      },
      "source": [
        "##use convert_to_spectrogram and convert every raw sequence in X_train_pad_seq and X_test_pad-seq.\n",
        "## save those all in the X_train_spectrogram and X_test_spectrogram ( These two arrays must be numpy arrays)\n",
        "\n",
        "X_train_spectrogram = None\n",
        "X_test_spectrogram = None\n",
        "for ind , val in enumerate(X_train_pad_seq) :\n",
        "  if ind==0:\n",
        "    X_train_spectrogram = convert_to_spectrogram(X_train_pad_seq[ind]).reshape(1,64, 35)\n",
        "    continue\n",
        "  X_train_spectrogram = np.concatenate((X_train_spectrogram, convert_to_spectrogram(X_train_pad_seq[ind]).reshape(1,64, 35)), axis=0)\n",
        "for ind , val in enumerate(X_test_pad_seq) :\n",
        "  if ind==0:\n",
        "    X_test_spectrogram = convert_to_spectrogram(X_test_pad_seq[ind]).reshape(1,64, 35)\n",
        "    continue\n",
        "  X_test_spectrogram = np.concatenate((X_test_spectrogram, convert_to_spectrogram(X_test_pad_seq[ind]).reshape(1,64, 35)), axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZyFH3hoUkPb"
      },
      "source": [
        "#np.save('X_train_spectrogram.npy',X_train_spectrogram)\n",
        "#np.save('X_test_spectrogram.npy',X_test_spectrogram)\n",
        "X_train_spectrogram = np.load('X_train_spectrogram.npy',allow_pickle=True)\n",
        "X_test_spectrogram = np.load('X_test_spectrogram.npy',allow_pickle=True) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zr1ynYZnaNpj"
      },
      "source": [
        "<font size=4>Grader function 6 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oniXBXcsaNpk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5146b3a8-d8ba-4b86-fa5c-5452479c3112"
      },
      "source": [
        "def grader_spectrogram():\n",
        "    flag_shape = (X_train_spectrogram.shape==(1400,64, 35)) and (X_test_spectrogram.shape == (600, 64, 35))\n",
        "    return flag_shape\n",
        "grader_spectrogram()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxlEVyIYaNpt"
      },
      "source": [
        "<pre>\n",
        "Now we have\n",
        "\n",
        "Train data: X_train_spectrogram and y_train  \n",
        "Test data: X_test_spectrogram and y_test   \n",
        "\n",
        "We will create a LSTM model which takes this input. \n",
        "\n",
        "Task:\n",
        "\n",
        "1. Create an LSTM network which takes \"X_train_spectrogram\" as input and has to return output at every time step. \n",
        "2. Average the output of every time step and give this to the Dense layer of any size. \n",
        "(ex: Output from LSTM will be  (#., time_steps, features) average the output of every time step i.e, you should get (#.,time_steps) \n",
        "and then pass to dense layer )\n",
        "3. give the above output to Dense layer of size 10( output layer) and train the network with sparse categorical cross entropy.  \n",
        "4. Use tensorboard to plot the graphs of loss and metric(use micro F1 score as metric) and histograms of gradients. \n",
        "5. make sure that it won't overfit. \n",
        "6. You are free to include any regularization\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaQjaiiGaNpv"
      },
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Dense,Embedding, GlobalAveragePooling1D\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow_addons as tfa\n",
        "tf.keras.backend.clear_session()\n",
        "input_padded = Input(shape = (64, 35),name= 'input_padded')\n",
        "lstm = LSTM(50 , return_sequences=True)(input_padded)\n",
        "averaging = GlobalAveragePooling1D(data_format='channels_first')(lstm)\n",
        "dense = Dense(50, 'relu')(averaging)\n",
        "dropout = tf.keras.layers.Dropout(0.5)(dense)\n",
        "output = Dense(10, 'softmax')(dropout)\n",
        "model = Model(inputs = input_padded, outputs = output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "862fP2e-aNp3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2070a98b-c8b6-4f0b-dbdc-bbe645a60fa5"
      },
      "source": [
        "\n",
        "import datetime\n",
        "earlystop = EarlyStopping(monitor='val_accuracy', min_delta=0.00001, patience=3, verbose=1,mode='auto')\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "#microf1score = tfa.metrics.F1Score(num_classes=10, threshold=0.5 , average='micro')\n",
        "model.compile(optimizer=optimizer,loss='sparse_categorical_crossentropy',metrics=['accuracy',microf1],run_eagerly=True)\n",
        "\n",
        "log_dir=\"logs/fit/\" + 'model2.'+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=1, write_graph=True,write_grads=True)\n",
        "y_train = [int(i) for i in y_train]\n",
        "y_test = [int(i) for i in y_test]\n",
        "model.fit(x=X_train_spectrogram,y=np.array(y_train),epochs=100,validation_data=(X_test_spectrogram,np.array(y_test) ),callbacks=[earlystop,tensorboard_callback],batch_size=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n",
            "Epoch 1/100\n",
            "140/140 [==============================] - 46s 331ms/step - loss: 2.2521 - accuracy: 0.1871 - microf1: 0.1871 - val_loss: 2.1320 - val_accuracy: 0.3700 - val_microf1: 0.3700\n",
            "Epoch 2/100\n",
            "140/140 [==============================] - 47s 334ms/step - loss: 1.9838 - accuracy: 0.3186 - microf1: 0.3186 - val_loss: 1.7317 - val_accuracy: 0.4467 - val_microf1: 0.4467\n",
            "Epoch 3/100\n",
            "140/140 [==============================] - 48s 342ms/step - loss: 1.7146 - accuracy: 0.3843 - microf1: 0.3843 - val_loss: 1.5075 - val_accuracy: 0.5517 - val_microf1: 0.5517\n",
            "Epoch 4/100\n",
            "140/140 [==============================] - 55s 395ms/step - loss: 1.5826 - accuracy: 0.3993 - microf1: 0.3993 - val_loss: 1.3543 - val_accuracy: 0.5683 - val_microf1: 0.5683\n",
            "Epoch 5/100\n",
            "140/140 [==============================] - 54s 388ms/step - loss: 1.4737 - accuracy: 0.4421 - microf1: 0.4421 - val_loss: 1.3426 - val_accuracy: 0.5867 - val_microf1: 0.5867\n",
            "Epoch 6/100\n",
            "140/140 [==============================] - 54s 388ms/step - loss: 1.4205 - accuracy: 0.4679 - microf1: 0.4679 - val_loss: 1.2719 - val_accuracy: 0.5567 - val_microf1: 0.5567\n",
            "Epoch 7/100\n",
            "140/140 [==============================] - 54s 388ms/step - loss: 1.3780 - accuracy: 0.4886 - microf1: 0.4886 - val_loss: 1.1522 - val_accuracy: 0.6600 - val_microf1: 0.6600\n",
            "Epoch 8/100\n",
            "140/140 [==============================] - 47s 333ms/step - loss: 1.2935 - accuracy: 0.5271 - microf1: 0.5271 - val_loss: 1.1017 - val_accuracy: 0.6850 - val_microf1: 0.6850\n",
            "Epoch 9/100\n",
            "140/140 [==============================] - 46s 332ms/step - loss: 1.2403 - accuracy: 0.5471 - microf1: 0.5471 - val_loss: 1.0477 - val_accuracy: 0.7083 - val_microf1: 0.7083\n",
            "Epoch 10/100\n",
            "140/140 [==============================] - 48s 340ms/step - loss: 1.1506 - accuracy: 0.5714 - microf1: 0.5714 - val_loss: 0.9611 - val_accuracy: 0.7000 - val_microf1: 0.7000\n",
            "Epoch 11/100\n",
            "140/140 [==============================] - 55s 392ms/step - loss: 1.1112 - accuracy: 0.5871 - microf1: 0.5871 - val_loss: 0.9662 - val_accuracy: 0.6950 - val_microf1: 0.6950\n",
            "Epoch 12/100\n",
            "140/140 [==============================] - 47s 337ms/step - loss: 1.1097 - accuracy: 0.5943 - microf1: 0.5943 - val_loss: 0.9105 - val_accuracy: 0.7500 - val_microf1: 0.7500\n",
            "Epoch 13/100\n",
            "140/140 [==============================] - 46s 332ms/step - loss: 1.0499 - accuracy: 0.6300 - microf1: 0.6300 - val_loss: 0.9126 - val_accuracy: 0.6967 - val_microf1: 0.6967\n",
            "Epoch 14/100\n",
            "140/140 [==============================] - 54s 384ms/step - loss: 1.0231 - accuracy: 0.6386 - microf1: 0.6386 - val_loss: 0.8278 - val_accuracy: 0.7717 - val_microf1: 0.7717\n",
            "Epoch 15/100\n",
            "140/140 [==============================] - 47s 334ms/step - loss: 1.0091 - accuracy: 0.6336 - microf1: 0.6336 - val_loss: 0.8027 - val_accuracy: 0.7833 - val_microf1: 0.7833\n",
            "Epoch 16/100\n",
            "140/140 [==============================] - 47s 334ms/step - loss: 0.9816 - accuracy: 0.6536 - microf1: 0.6536 - val_loss: 0.8030 - val_accuracy: 0.7600 - val_microf1: 0.7600\n",
            "Epoch 17/100\n",
            "140/140 [==============================] - 54s 386ms/step - loss: 0.9371 - accuracy: 0.6700 - microf1: 0.6700 - val_loss: 0.8080 - val_accuracy: 0.7650 - val_microf1: 0.7650\n",
            "Epoch 18/100\n",
            "140/140 [==============================] - 46s 330ms/step - loss: 0.9339 - accuracy: 0.6750 - microf1: 0.6750 - val_loss: 0.7754 - val_accuracy: 0.7867 - val_microf1: 0.7867\n",
            "Epoch 19/100\n",
            "140/140 [==============================] - 54s 386ms/step - loss: 0.9072 - accuracy: 0.6907 - microf1: 0.6907 - val_loss: 0.7329 - val_accuracy: 0.7883 - val_microf1: 0.7883\n",
            "Epoch 20/100\n",
            "140/140 [==============================] - 46s 332ms/step - loss: 0.9006 - accuracy: 0.6879 - microf1: 0.6879 - val_loss: 0.7229 - val_accuracy: 0.7950 - val_microf1: 0.7950\n",
            "Epoch 21/100\n",
            "140/140 [==============================] - 54s 388ms/step - loss: 0.8706 - accuracy: 0.6907 - microf1: 0.6907 - val_loss: 0.6824 - val_accuracy: 0.8083 - val_microf1: 0.8083\n",
            "Epoch 22/100\n",
            "140/140 [==============================] - 53s 383ms/step - loss: 0.8531 - accuracy: 0.6993 - microf1: 0.6993 - val_loss: 0.7092 - val_accuracy: 0.8000 - val_microf1: 0.8000\n",
            "Epoch 23/100\n",
            "140/140 [==============================] - 53s 380ms/step - loss: 0.8385 - accuracy: 0.6979 - microf1: 0.6979 - val_loss: 0.6897 - val_accuracy: 0.8167 - val_microf1: 0.8167\n",
            "Epoch 24/100\n",
            "140/140 [==============================] - 46s 327ms/step - loss: 0.8342 - accuracy: 0.7136 - microf1: 0.7136 - val_loss: 0.6848 - val_accuracy: 0.8033 - val_microf1: 0.8033\n",
            "Epoch 25/100\n",
            "140/140 [==============================] - 46s 328ms/step - loss: 0.7885 - accuracy: 0.7164 - microf1: 0.7164 - val_loss: 0.6609 - val_accuracy: 0.7967 - val_microf1: 0.7967\n",
            "Epoch 26/100\n",
            "140/140 [==============================] - 54s 384ms/step - loss: 0.8336 - accuracy: 0.7171 - microf1: 0.7171 - val_loss: 0.6576 - val_accuracy: 0.7817 - val_microf1: 0.7817\n",
            "Epoch 00026: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f86cc545a10>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtMsbGs3aNp_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSl8ZOXjaNqJ"
      },
      "source": [
        "### 3. data augmentation  \n",
        "<pre>\n",
        "Till now we have done with 2000 samples only. It is very less data. We are giving the process of generating augmented data below.\n",
        "\n",
        "There are two types of augmentation:\n",
        "1. time stretching - Time stretching either increases or decreases the length of the file. For time stretching we move the file 30% faster or slower\n",
        "2. pitch shifting - pitch shifting moves the frequencies higher or lower. For pitch shifting we shift up or down one half-step.\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jR4JSEDgaNqK"
      },
      "source": [
        "## generating augmented data. \n",
        "def generate_augmented_data(file_path):\n",
        "    augmented_data = []\n",
        "    samples = load_wav(file_path,get_duration=False)\n",
        "    for time_value in [0.7, 1, 1.3]:\n",
        "        for pitch_value in [-1, 0, 1]:\n",
        "            time_stretch_data = librosa.effects.time_stretch(samples, rate=time_value)\n",
        "            final_data = librosa.effects.pitch_shift(time_stretch_data, sr=sample_rate, n_steps=pitch_value)\n",
        "            augmented_data.append(final_data)\n",
        "    return augmented_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRdefb-SaNqS"
      },
      "source": [
        "temp_path = df_audio.iloc[0].path\n",
        "aug_temp = generate_augmented_data(temp_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ml20MYWAnxwy"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df_audio['path'], df_audio['label'], test_size=0.2, random_state=45,stratify=df_audio['label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzdG3iS-aNqc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98d62b39-681f-4b80-fad0-7aeb483b3a55"
      },
      "source": [
        "#create augmmented data\n",
        "X_train_aug = None\n",
        "for ind , val in enumerate(X_train) :\n",
        "  if ind==0:\n",
        "    X_train_aug = generate_augmented_data(val)\n",
        "    continue\n",
        "  X_train_aug = np.concatenate((X_train_aug, generate_augmented_data(val)), axis=0)\n",
        "\n",
        "X_test_notaug = []\n",
        "for ind , val in enumerate(X_test) :\n",
        "  X_test_notaug.append(load_wav(val,get_duration=False))\n",
        "\n",
        "np.save('X_train_aug.npy',X_train_aug)\n",
        "np.save('X_test_not_aug.npy',X_test_notaug)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order, subok=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNlvwfzVmQmi"
      },
      "source": [
        "#X_train_aug = np.load('X_train_aug.npy',allow_pickle=True)\n",
        "X_test_notaug = np.load('X_test_not_aug.npy',allow_pickle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7s0unPb65dR",
        "outputId": "333cf484-1453-4ed4-8733-ec4161ee4195"
      },
      "source": [
        "X_test_notaug.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400,)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSIyBTgcu0FN"
      },
      "source": [
        "X_train_aug_pad_seq = None\n",
        "X_train_aug_mask = None\n",
        "for k,i in enumerate(X_train_aug):\n",
        "  if k == 0:\n",
        "    X_train_aug_pad_seq =  np.append( i[0:17640],np.zeros(max( 17640 - i.shape[0] , 0))).reshape(1,-1)\n",
        "    X_train_aug_mask = np.append( np.ones(i[0:17640].shape[0]),np.zeros(max( 17640 - i.shape[0] , 0))).reshape(1,-1)\n",
        "    continue\n",
        "  X_train_aug_pad_seq = np.append(X_train_aug_pad_seq , np.append( i[0:17640],np.zeros(max( 17640 - i.shape[0] , 0))).reshape(1,-1), axis=0)\n",
        "  X_train_aug_mask =  np.append(X_train_aug_mask,np.append( np.ones(i[0:17640].shape[0]),np.zeros(max( 17640 - i.shape[0] , 0))).reshape(1,-1), axis=0)\n",
        "\n",
        "X_test_aug_pad_seq = None\n",
        "X_test_aug_mask = None\n",
        "for k,i in enumerate(X_test_notaug):\n",
        "  if k == 0:\n",
        "    X_test_aug_pad_seq =  np.append( i[0:17640],np.zeros(max( 17640 - i.shape[0] , 0))).reshape(1,-1)\n",
        "    X_test_aug_mask = np.append( np.ones(i[0:17640].shape[0]),np.zeros(max( 17640 - i.shape[0] , 0))).reshape(1,-1)\n",
        "    continue\n",
        "  X_test_aug_pad_seq = np.append(X_test_aug_pad_seq , np.append( i[0:17640],np.zeros(max( 17640 - i.shape[0] , 0))).reshape(1,-1), axis=0)\n",
        "  X_test_aug_mask =  np.append(X_test_aug_mask,np.append( np.ones(i[0:17640].shape[0]),np.zeros(max( 17640 - i.shape[0] , 0))).reshape(1,-1), axis=0)\n",
        "\n",
        "np.save('X_train_aug_mask.npy',X_train_aug_mask)\n",
        "np.save('X_test_aug_mask.npy',X_test_aug_mask)\n",
        "np.save('X_train_aug_pad_seq.npy',X_train_aug_pad_seq)\n",
        "np.save('X_test_aug_pad_seq.npy',X_test_aug_pad_seq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1nvZLYAmhZI"
      },
      "source": [
        "# np.save('X_train_aug_mask.npy',X_train_aug_mask)\n",
        "# np.save('X_test_aug_mask.npy',X_test_aug_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Oty4lYEi2yD"
      },
      "source": [
        "# np.save('X_train_aug_pad_seq.npy',X_train_aug_pad_seq)\n",
        "# np.save('X_test_aug_pad_seq.npy',X_test_aug_pad_seq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qaw4dF45lhoP"
      },
      "source": [
        "X_train_aug_mask = np.load('X_train_aug_mask.npy',allow_pickle=True)\n",
        "X_test_aug_mask = np.load('X_test_aug_mask.npy',allow_pickle=True)\n",
        "X_train_aug_pad_seq = np.load('X_train_aug_pad_seq.npy',allow_pickle=True)\n",
        "X_test_aug_pad_seq = np.load('X_test_aug_pad_seq.npy',allow_pickle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeOhR3QG35sZ",
        "outputId": "f1cbd664-7ef5-42bf-8713-a9338ce3146f"
      },
      "source": [
        "np.array(y_test).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400,)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrvdbVGHmDr0"
      },
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Dense,Embedding\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "max_length  = 17640\n",
        "input_padded = Input(shape = (max_length, 1),name= 'input_padded')\n",
        "input_masked = Input(shape = (max_length), dtype='bool' ,name= 'input_masked')\n",
        "lstm = LSTM(50)(input_padded, mask = input_masked)\n",
        "dense = Dense(50, 'relu')(lstm)\n",
        "output = Dense(10, 'softmax')(dense)\n",
        "model = Model(inputs = [input_padded, input_masked], outputs = output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bs1MPS0XmDr0",
        "outputId": "f4fc7c36-753b-4974-fcbc-d2b3a081139f"
      },
      "source": [
        "## as discussed above, please write the LSTM\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_padded (InputLayer)       [(None, 17640, 1)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_masked (InputLayer)       [(None, 17640)]      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_16 (LSTM)                  (None, 50)           10400       input_padded[0][0]               \n",
            "                                                                 input_masked[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 50)           2550        lstm_16[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_11 (Dense)                (None, 10)           510         dense_10[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 13,460\n",
            "Trainable params: 13,460\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLtNiKs29Nxo"
      },
      "source": [
        "y_train_new = []\n",
        "for i in y_train:\n",
        "  y_train_new.extend([i]*9)\n",
        "y_train = y_train_new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rmu76BpPuyev",
        "outputId": "24ca521c-8db9-4c0e-eecb-4a1c90d33eb9"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "y_train_fit = np.array([ [int(i)] for i in y_train])\n",
        "enc.fit(y_train_fit)\n",
        "\n",
        "enc.categories_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1IsE5kmuyet"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def microf1(y_true, y_pred):\n",
        "    y_true=y_true.numpy()\n",
        "    y_true = enc.transform(y_true)\n",
        "    y_true = y_true.todense()\n",
        "    y_pred = y_pred.numpy()\n",
        "    y_new_pred = np.array([])\n",
        "    for i,j in enumerate(y_pred):\n",
        "      if i == 0:\n",
        "        y_new_pred =  np.zeros(len(j)).reshape(1,-1)\n",
        "        y_new_pred[0][np.argmax(j)] = 1 \n",
        "        continue\n",
        "      y_new_append = np.zeros(len(j))\n",
        "      y_new_append[np.argmax(j)] = 1\n",
        "      y_new_pred = np.append(y_new_pred,y_new_append.reshape(1,-1), axis=0)\n",
        "      \n",
        "    return f1_score(y_true, y_new_pred, average='micro')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbdimPQHo5hB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53b806fa-df7b-4169-fb77-543df9c59cbb"
      },
      "source": [
        "#train your model\n",
        "import datetime\n",
        "earlystop = EarlyStopping(monitor='val_accuracy', min_delta=0.00001, patience=2, verbose=1,mode='auto')\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "#microf1score = tfa.metrics.F1Score(num_classes=3, threshold=0.5 , average='micro')\n",
        "model.compile(optimizer=optimizer,loss='sparse_categorical_crossentropy',metrics=['accuracy',microf1],run_eagerly=True)\n",
        "y_train = [int(i) for i in y_train]\n",
        "y_test = [int(i) for i in y_test]\n",
        "model.fit(x=[X_train_aug_pad_seq.reshape(14400,17640,1),X_train_aug_mask.astype('bool')],y=np.array(y_train),epochs=50,validation_data=([X_test_aug_pad_seq.reshape(400,17640,1),X_test_aug_mask.astype('bool')],np.array(y_test) ),callbacks=[earlystop],batch_size = 32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "450/450 [==============================] - 799s 2s/step - loss: 2.3030 - accuracy: 0.0960 - microf1: 0.0960 - val_loss: 2.3026 - val_accuracy: 0.0975 - val_microf1: 0.0986\n",
            "Epoch 2/50\n",
            "450/450 [==============================] - 779s 2s/step - loss: 2.3029 - accuracy: 0.1003 - microf1: 0.1003 - val_loss: 2.3027 - val_accuracy: 0.1000 - val_microf1: 0.1034\n",
            "Epoch 3/50\n",
            "450/450 [==============================] - 765s 2s/step - loss: 2.3029 - accuracy: 0.0951 - microf1: 0.0951 - val_loss: 2.3025 - val_accuracy: 0.1000 - val_microf1: 0.0986\n",
            "Epoch 4/50\n",
            "450/450 [==============================] - 776s 2s/step - loss: 2.3028 - accuracy: 0.0947 - microf1: 0.0947 - val_loss: 2.3025 - val_accuracy: 0.0975 - val_microf1: 0.1010\n",
            "Epoch 00004: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4bbffde5d0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rHXWJszux30"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K88ea07r1mTG"
      },
      "source": [
        "spectrogram features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDHB9Jk7xu90"
      },
      "source": [
        "##use convert_to_spectrogram and convert every raw sequence in X_train_aug_pad_seq and X_test_pad-seq.\n",
        "## save those all in the X_train_spectrogram and X_test_spectrogram ( These two arrays must be numpy arrays)\n",
        "\n",
        "X_train_aug_spectrogram = None\n",
        "X_test_spectrogram = None\n",
        "for ind , val in enumerate(X_train_aug_pad_seq) :\n",
        "  if ind==0:\n",
        "    X_train_aug_spectrogram = convert_to_spectrogram(X_train_aug_pad_seq[ind]).reshape(1,64, 35)\n",
        "    continue\n",
        "  X_train_aug_spectrogram = np.concatenate((X_train_aug_spectrogram, convert_to_spectrogram(X_train_aug_pad_seq[ind]).reshape(1,64, 35)), axis=0)\n",
        "np.save('X_train_aug_spectrogram.npy',X_train_aug_spectrogram)\n",
        "for ind , val in enumerate(X_test_aug_pad_seq) :\n",
        "  if ind==0:\n",
        "    X_test_aug_spectrogram = convert_to_spectrogram(X_test_aug_pad_seq[ind]).reshape(1,64, 35)\n",
        "    continue\n",
        "  X_test_aug_spectrogram = np.concatenate((X_test_aug_spectrogram, convert_to_spectrogram(X_test_aug_pad_seq[ind]).reshape(1,64, 35)), axis=0)\n",
        "np.save('X_test_aug_spectrogram.npy',X_test_aug_spectrogram)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwfHHsFqxbEV"
      },
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Dense,Embedding, GlobalAveragePooling1D\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow_addons as tfa\n",
        "tf.keras.backend.clear_session()\n",
        "input_padded = Input(shape = (64, 35),name= 'input_padded')\n",
        "lstm = LSTM(50 , return_sequences=True)(input_padded)\n",
        "averaging = GlobalAveragePooling1D(data_format='channels_first')(lstm)\n",
        "dense = Dense(50, 'relu')(averaging)\n",
        "dropout = tf.keras.layers.Dropout(0.5)(dense)\n",
        "output = Dense(10, 'softmax')(dropout)\n",
        "model = Model(inputs = input_padded, outputs = output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xg-2l9D_xbEi",
        "outputId": "d4d65a67-9826-4ec5-aa2d-99dc02da002a"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "y_train_fit = np.array([ [int(i)] for i in y_train])\n",
        "enc.fit(y_train_fit)\n",
        "enc.categories_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lS4OzWxIxbEj",
        "outputId": "4db799f9-fc11-4d89-de68-374caa49e108"
      },
      "source": [
        "\n",
        "import datetime\n",
        "earlystop = EarlyStopping(monitor='val_accuracy', min_delta=0.000001, patience=3, verbose=1,mode='auto')\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "#microf1score = tfa.metrics.F1Score(num_classes=10, threshold=0.5 , average='micro')\n",
        "model.compile(optimizer=optimizer,loss='sparse_categorical_crossentropy',metrics=['accuracy',microf1],run_eagerly=True)\n",
        "\n",
        "log_dir=\"logs/fit/\" + 'model2.'+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=1, write_graph=True,write_grads=True)\n",
        "y_train = [int(i) for i in y_train]\n",
        "y_test = [int(i) for i in y_test]\n",
        "model.fit(x=X_train_aug_spectrogram,y=np.array(y_train),epochs=100,validation_data=(X_test_aug_spectrogram,np.array(y_test) ),callbacks=[earlystop,tensorboard_callback],batch_size=30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n",
            "Epoch 1/100\n",
            "480/480 [==============================] - 124s 258ms/step - loss: 1.9876 - accuracy: 0.2952 - microf1: 0.2952 - val_loss: 1.2342 - val_accuracy: 0.6350 - val_microf1: 0.6286\n",
            "Epoch 2/100\n",
            "480/480 [==============================] - 120s 250ms/step - loss: 1.2854 - accuracy: 0.5558 - microf1: 0.5558 - val_loss: 0.9437 - val_accuracy: 0.7400 - val_microf1: 0.7381\n",
            "Epoch 3/100\n",
            "480/480 [==============================] - 123s 256ms/step - loss: 1.0672 - accuracy: 0.6299 - microf1: 0.6299 - val_loss: 0.7195 - val_accuracy: 0.7600 - val_microf1: 0.7619\n",
            "Epoch 4/100\n",
            "480/480 [==============================] - 123s 257ms/step - loss: 0.9452 - accuracy: 0.6729 - microf1: 0.6729 - val_loss: 0.6952 - val_accuracy: 0.7900 - val_microf1: 0.7857\n",
            "Epoch 5/100\n",
            "480/480 [==============================] - 120s 250ms/step - loss: 0.8883 - accuracy: 0.6905 - microf1: 0.6905 - val_loss: 0.6124 - val_accuracy: 0.7825 - val_microf1: 0.7786\n",
            "Epoch 6/100\n",
            "480/480 [==============================] - 122s 254ms/step - loss: 0.8371 - accuracy: 0.7108 - microf1: 0.7108 - val_loss: 0.5956 - val_accuracy: 0.7950 - val_microf1: 0.7952\n",
            "Epoch 7/100\n",
            "480/480 [==============================] - 121s 252ms/step - loss: 0.8011 - accuracy: 0.7196 - microf1: 0.7196 - val_loss: 0.5794 - val_accuracy: 0.8250 - val_microf1: 0.8238\n",
            "Epoch 8/100\n",
            "480/480 [==============================] - 121s 252ms/step - loss: 0.7665 - accuracy: 0.7326 - microf1: 0.7326 - val_loss: 0.5663 - val_accuracy: 0.7950 - val_microf1: 0.7905\n",
            "Epoch 9/100\n",
            "480/480 [==============================] - 122s 255ms/step - loss: 0.7437 - accuracy: 0.7383 - microf1: 0.7383 - val_loss: 0.5776 - val_accuracy: 0.7875 - val_microf1: 0.7881\n",
            "Epoch 10/100\n",
            "480/480 [==============================] - 120s 251ms/step - loss: 0.7215 - accuracy: 0.7428 - microf1: 0.7428 - val_loss: 0.5404 - val_accuracy: 0.8100 - val_microf1: 0.8095\n",
            "Epoch 00010: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f86cc332390>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZckytZsraNqk"
      },
      "source": [
        "As discussed above, for one data point, we will get 9 augmented data points.  \n",
        "\n",
        "Split data into train and test (80-20 split)\n",
        "\n",
        "We have 2000 data points(1600 train points, 400 test points) \n",
        "\n",
        "Do augmentation only on train data, after augmentation we will get 14400 train points. \n",
        "\n",
        "do the above steps i.e training with raw data and spectrogram data with augmentation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdKXVRlpaNql"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}